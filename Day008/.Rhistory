# data() r이 제공하는 데이터셋 목록 출력됨
str(iris)
?iris
## 데이터 내용 확인
head(iris, 10)
# 필요 패키지 설치 및 로딩
library(dplyr)
library(ggplot2)
library(ggplot2)
install.packages('readr')
install.packages('descr')
library(readr)
library(descr)
# 데이터 불러오기
train <- readr::read_csv('C:/k_digital/data/titanic/train.csv')
test <- read_csv('C:/k_digital/data/titanic/test.csv')
#
head(train)
head(test)
str(train)
full <- bind_rows(train, test) # rbind()와 cbind()
# 변수의 의미 파악
names(train)
names(test)
# 사본 titanic
titanic <- train[, c(2, 3, 5:8, 12)]
# 변수 속성 변경
table(titanic$Survived)
table(titanic$Pclass)
table(titanic$Embarked)
titanic <- titanic %>%
mutate(Survived = factor(Survived),
Pclass = factor(Pclass),
Sex = factor(Sex),
Embarked = factor(Embarked))
str(titanic)
titanic <- as.data.frame(titanic)
summary(titanic)
# 문제정의
## 전처리: 결측치와 이상치 처리
mean(titanic)
# 문제정의
## 전처리: 결측치와 이상치 처리
mean(titanic, na.rm = T)
# 문제정의
## 전처리: 결측치와 이상치 처리
mean(titanic, na.rm = F)
# 문제정의
## 전처리: 결측치와 이상치 처리
mean(titanic$Age, na.rm = T)
# 문제정의
## 전처리: 결측치와 이상치 처리
mean(titanic$Age)
titanic$Age <- ifelse(titanic$Age == NA, mean(titanic$Age, na.rm = T), titanic$Age)
titanic$Embarked <- ifelse(titanic$Embarked == NA,'S', titanic$Embarked)
summary(titanic)
# 사본 titanic
titanic <- train[, c(2, 3, 5:8, 12)]
titanic <- titanic %>%
mutate(Survived = factor(Survived),
Pclass = factor(Pclass),
Sex = factor(Sex),
Embarked = factor(Embarked)) # 변수들을 한 번에 팩터로 변환함 #
titanic <- as.data.frame(titanic)
summary(titanic)
titanic$Age <- ifelse(is.na(titanic$Age), mean(titanic$Age, na.rm = T), titanic$Age)
titanic$Embarked <- ifelse(is.na(titanic$Embarked),'S', titanic$Embarked)
summary(titanic)
titanic <- titanic %>%
mutate(Survived = factor(Survived),
Pclass = factor(Pclass),
Sex = factor(Sex),
Embarked = factor(Embarked)) # 변수들을 한 번에 팩터로 변환함 #
# 사본 titanic
titanic <- train[, c(2, 3, 5:8, 12)]
titanic <- titanic %>%
mutate(Survived = factor(Survived),
Pclass = factor(Pclass),
Sex = factor(Sex),
Embarked = factor(Embarked)) # 변수들을 한 번에 팩터로 변환함 #
titanic <- as.data.frame(titanic)
titanic$Age <- ifelse(is.na(titanic$Age), mean(titanic$Age, na.rm = T), titanic$Age)
head(titanic, 10)
titanic$Embarked <- ifelse(is.na(titanic$Embarked), 3, titanic$Embarked)
summary(titanic)
titanic <- titanic %>%
mutate(Survived = factor(Survived),
Pclass = factor(Pclass),
Sex = factor(Sex),
Embarked = factor(Embarked)) # 변수들을 한 번에 팩터로 변환함 #
head(titanic, 10)
## 1. 생존비율 - 사망과 생존의 비율
proportions(table(titanic$Survived))
## 1. 생존비율 - 사망과 생존의 비율
proportions(table(titanic$Survived))* 1000
## 1. 생존비율 - 사망과 생존의 비율
proportions(table(titanic$Survived))* 100
ggplot(tatanic, aes(x = Survived)) + geom_point()
ggplot(titanic, aes(x = Survived)) + geom_point()
ggplot(titanic, aes(Survived)) + geom_point()
## 2. 성별에 따라
xtabs(Sex ~ Survived, titanic)
sapply(titanic, FUN = function(x)) {
sapply(titanic, FUN = function(x) {
sum(is.na(x)) # T = 1, F = 0
})
## 2. 성별에 따라
xtabs(Sex ~ Survived, titanic)
## 2. 성별에 따라
xtabs(~Sex, Survived, titanic)
xtabs(~ Sex, Survived)
## 2. 성별에 따라
xtabs(~ titanic$Sex, titanic$Survived)
## 2. 성별에 따라
xtabs(~ titanic$Sex, titanic$Survived == 1)
## 2. 성별에 따라
gender <- ggplot(titanic , aes(x = Survived, fill = Sex, width = .8)) + geom_bar()
gender
xtabs(~ Sex + Survived, titanic)
## 3. 선실 등급에 따른 생존여부
xtabs(~Pclass + Survived, titanic)
pcalss <- ggplot(titanic, aes(x = Survived, fill = Pclass)) + geom_bar()
pclass <- ggplot(titanic, aes(x = Survived, fill = Pclass)) + geom_bar()
pclass
rm(pcalss)
## 4. 동반가족 수에 따른 생존여부
xtabs(~Sibsp, Parch + Survived, titanic)
## 4. 동반가족 수에 따른 생존여부
xtabs(~Sibsp + Parch + Survived, titanic)
## 4. 동반가족 수에 따른 생존여부
xtabs(~SibSp + Parch + Survived, titanic)
ggplot(titanic, aes(x = SibSp, y = Parch, fill = Survived)) + geom_bar()
## 5. 승선항에 따른 생존여부
xtabs(~ Survived + Embarked, titanic)
ggplot(titanic, aes(x = Survived, fill = Embarked)) + geom_bar()
ggplot(titanic, aes(x = SibSp, y = Parch, fill = factor(Survived)) + geom_bar()
ggplot(titanic, aes(x = SibSp, y = Parch, fill = factor(Survived)) + geom_bar()
ggplot(titanic, aes(x = Survived, fill = factor(SibSp)) + geom_bar()
ggplot(titanic, aes(x = Survived, fill = factor(Parch)) + geom_bar()
ggplot(titanic, aes(x = Survived, fill = SibSp) + geom_bar()
familysi <- ggplot(titanic, aes(x = Survived, fill = SibSp) + geom_bar()
familysi <- ggplot(titanic, aes(x = Survived, fill = factor(SibSp)) + geom_bar()
familysi <- ggplot(titanic, aes(x = Survived, fill = factor(SibSp)) + geom_bar()
ggplot(titanic, aes(Survived)) + geom_point()
## 1. 생존비율 - 사망과 생존의 비율
proportions(table(titanic$Survived))* 100
titanic %>%
group_by(Sex) %>%
summarise(mean = mean(Survived))
c <- titanic %>%
group_by(Pclass) %>%
summarise(mean = mean(Survived))
pie(c$mean)
familysi <- ggplot(titanic, aes(x = Survived, fill = factor(SibSp))) + geom_bar()
familysi
ggplot(titanic, aes(x = Survived, fill = factor(Parch))) + geom_bar()
fam <- titanic$SibSp + titanic$Parch
titanic$fam <- fam
as.factor(fam)
b <- titanic %>%
group_by(fam) %>%
summarise(mean = mean(Survived))
titanic$fam <- as.factor(fam)
b <- titanic %>%
group_by(fam) %>%
summarise(mean = mean(Survived))
a <- as.data.frame(titanic %>%
group_by(Embarked) %>%
summarise(mean = mean(Survived)))
a
ggplot(a,aes(x=a$Embarked,y=a$mean)) + geom_col()
ggplot(titanic, aes(x = Survived, fill = fam)) + geom_bar()
titanic$fam <- as.numeric(fam)
b <- titanic %>%
group_by(fam) %>%
summarise(mean = mean(Survived))
b <- titanic %>%
group_by(fam) %>%
summarise(mean = n(Survived))
titanic$fam <- as.factor(fam)
b <- titanic %>%
group_by(Survived, fam) %>%
summarise(cnt = count(Survived))
b <- titanic %>%
group_by(fam) %>%
summarise(cnt = count(Survived))
b
titanic %>%
group_by(Sex) %>%
summarise(sum = sum(Survived))
titanic %>%
group_by(Sex) %>%
count(Survived)
titanic %>%
group_by(Pclass) %>%
count(Survived)
c <- titanic %>%
group_by(Pclass) %>%
count(Survived)
pie(c)
titanic %>%
group_by(fam) %>%
count(Survived)
b <- titanic %>%
group_by(fam) %>%
count(Survived)
pie(b$mean)
pie(b$n)
pie(c$n)
a <- as.data.frame(titanic %>%
group_by(Embarked) %>%
count(Survived))
ggplot(a,aes(x=a$Embarked,y=a$mean)) + geom_col()
ggplot(a,aes(x=a$Embarked,y=a$n)) + geom_col()
a
ggplot(a,aes(x=a$Embarked,y=a$n, fill = Survived)) + geom_col()
plot(iris$Species ~ ., data = iris) # iris$Species ~ ., 품종과 품종 제외한 모든 것을 비교 #
plot(iris$Species.Length, col = as.numeric(iris$Species))
plot(iris$Species.Length, col = as.numeric(iris$Species))
plot(iris$Sepal.Length, col = as.numeric(iris$Species))
install.packages('caret')
library(caret)
?featurePlot
featurePlot(iris[, 1:4], iris$Species, 'ellipse')
# 시각화 - 다변량 상관분석
plot(iris)
plot(iris$Sepal.Length, col = as.numeric(iris$Species))
plot(iris$Sepal.Width, col = as.numeric(iris$Species))
plot(iris$Petal.Length, col = as.numeric(iris$Species))
plot(iris$Petal.Width, col = as.numeric(iris$Species))
# 정규화 - 로그 변환, z-value
scale(iris[1:4])
cbind(as.data.frame(sacle(iris[1:4])), iris$Species)
cbind(as.data.frame(scale(iris[1:4])), iris$Species)
# PCA 차원축소 알고리즘 - 비지도 학습
p <- princomp(iris[, 1:4], cor = T)
summary(p)
plot(p, type = 'l')
# 품종 레벨 확인
levels(iris$Species)
# 분할: train과 test를 분리해서 학습한다.
# iris 행수
nrow(iris)
# 품종별 레코드 수
table(iris, 10)
# 품종별 레코드 수
table(iris$Species)
head(iris, 10)
tail(iris, 10)
iris_row_idx <- createDataPartition(iris$Species, 0.8, F)
iris_row_idx
iris_row_idx <- createDataPartition(iris$Species, p = 0.8, F)
str(iris_row_idx)
iris_row_idx <- createDataPartition(iris$Species, p = 0.8, F)
str(iris_row_idx)
iris_row_idx <- createDataPartition(iris$Species, p = 0.8, list = F)
str(iris_row_idx)
iris_train <- iris[iris_row_idx, ]
table(iris_train$Species)
iris_test <- iris[-iris_row_idx, ]
table(iris_test)
table(iris_test$Species)
# 의사결정 트리 패키지 설치
install.packages('rpart')
install.packages("rpart")
library(rpart)
# rpart(formula, data, control)
# 종속변수(반응변수) ~ 독립변수(설명변수)
model <- rpart(Species ~ ., data = iris_train, control = rpart.control(minsplit = 2)) # minsplit 분리 시 최소 데이터 #
model
# 시각화
install.packages('rpartplot')
# 시각화
install.packages('rpart.plot')
library(rpart.plot)
rpart.plot(model)
# 가지치키(CP)
## CP값 조회
model$cptable
model_prune <- prune(model, cp = 0.010)
model_prune
rpart.plot(model_prune)
# CP nsplit rel error xerror       xstd
# 1 0.5000      0    1.0000 1.2375 0.05202914
# 2 0.4500      1    0.5000 0.9375 0.06629126
# 3 0.0125      2    0.0500 0.0875 0.03209280
# 4 0.0100      5    0.0125 0.0875 0.03209280
model_prune <- prune(model, cp = 0.0100)
rpart.plot(model_prune)
# CP nsplit rel error xerror       xstd
# 1 0.5000      0    1.0000 1.2375 0.05202914
# 2 0.4500      1    0.5000 0.9375 0.06629126
# 3 0.0125      2    0.0500 0.0875 0.03209280
# 4 0.0100      5    0.0125 0.0875 0.03209280
model_prune <- prune(model, cp = 0.0125)
rpart.plot(model_prune)
# party 패키지 - ctree()
install.packages('party')
library(party)
# ctree(formula, data)
iris_ctree <- ctree(Species ~  .,data = iris_train)
iris_ctree
plot(iris_ctree, type = 'simple')
plot(iris_ctree)
# 예측하기: predict(model, new_data, type = class, prob)
str(iris_test)
predict(model, newdata = iris_test, type = class)
predict(model, newdata = iris_test, type = 'class')
# 실제값과 예측값을 데이터 프레임으로 생성
## actual: 실제 값 expect: 예측 값
actual <- iris_test$Species
expect <- predict(model, newdata = iris_test, type = 'class')
result_df <- data.frame(actual, expect)
result_df
# 혼동행렬
table(result_df)
#             expect
# actual       setosa versicolor virginica
# setosa         10          0         0
# versicolor      0          9         1
# virginica       0          0        10
# 정확도
(10 + 10 + 9) /nrow(iris_test)
# 데이터 불러오기: 클립보드 데이터를 데이터 프레임으로 변환
apple_df <- read.table(file = 'clipboard', header = T, seq = '\t', stringsAsFactors = T)
# 데이터 불러오기: 클립보드 데이터를 데이터 프레임으로 변환
apple_df <- read.table(file = 'clipboard', header = T, sep = '\t', stringsAsFactors = T)
summary(apple_df)
# 품종에 따른 무게 분포 시각화
boxplot(weight ~ model, data = apple_df, ylab = '무게')
boxplot(sugar ~ model, data = apple_df, ylab = '당도')
boxplot(acid ~ model, data = apple_df, ylab = '산도')
boxplot(color ~ model, data = apple_df, ylab = '색깔')
library(caret)
# 훈련 데이터 분리 (전체 데이터의 80%): apple_train_idx
apple_train_idx <- createDataPartition(apple_df, p = 0.8, list = F)
View(apple_train_idx)
View(apple_train_idx)
# 훈련 데이터 분리 (전체 데이터의 80%): apple_train_idx
apple_row_idx <- createDataPartition(apple_df$model, p = 0.8, list = F)
str(apple_row_idx)
View(apple_row_idx)
apple_train_idx <- apple_df[apple_row_idx, ]
table(apple_train_idx$model)
# 로얄후지   미시마   아오리     홍로     홍옥
# 4        4        4        4        4
apple_test_idx <- apple_df[-apple_row_idx, ]
table(apple_test_idx$model)
# 훈련 데이터를 기반으로 분류 모델 생성: rpart
# rpart(formula, data, control)
# 종속변수(반응변수) ~ 독립변수(설명변수)
amodel <- rpart(model ~ ., data = apple_train_idx, control = rpart.control(minsplit = 2))
amodel
# rpart.plot 시각화
rpart.plot(amodel)
# 실제값과 예측한 값 한 눈에 비교할 수 있는 데이터 프레임
amodel$cptable
# CP nsplit rel error xerror       xstd
# 1 0.2500      0    1.0000 1.2500 0.00000000
# 2 0.1875      3    0.2500 1.2500 0.00000000
# 3 0.0625      4    0.0625 0.1250 0.08385255
# 4 0.0100      5    0.0000 0.1875 0.09980450
aprune <- prune(amodel, cp = 0.0100)
aprune
rpart.plot(aprune)
library(party)
apple_ctree <- ctree(model ~ ., data = apple_train_idx)
apple_ctree
plot(apple_ctree)
predict(amodel, newdata = apple_test_idx, type = 'class')
#
library(readxl)
# load data
bike <- read.csv('C:/k_digital/data/SeoulBikeData.csv')
summary(bike)
# 회귀 - 예측
names(bike)
# 1       14       19       24       25
# 아오리   아오리     홍옥   미시마 로얄후지
actual <- apple_test_idx$model
expect <- predict(amodel, newdata = apple_test_idx, type = 'class')
result_df <- data.frame(actual, expect)
result_df
# 혼돈행렬
table(result_df)
# scatter plot: 온도와 자전거 대여수의 상관성
plot(x = bike$Temperature, y = bike$Rented.Bike.Count)
# 정확도
(1 + 1 + 1 + 1) / nrow(apple_test_idx)
# 선형 회귀 분석
## 회귀방정식 y = ax + b
lm(Rented.Bike.Count ~ Temperature, bike)
# Coefficients:
# (Intercept)  Temperature
# 329.95        29.08
summary(modle)
# Coefficients:
# (Intercept)  Temperature
# 329.95        29.08
summary(lm(Rented.Bike.Count ~ Temperature, bike))
# 선형 회귀 분석
## 회귀방정식 y = ax + b
bmodel<- lm(Rented.Bike.Count ~ Temperature, bike)
## 예측 y = ax + b
## a = 29.08 b = 329.95
temp_Temperature = 23
a = 29.08
b = 329.95
y = a * temp_Temperature + b
y
abline(a = b, b = a, col = 'red')
# 여러 개의 값을 이용한 예측
temperature_list = c(-10, 0, 10, 20, 30, 40)
new <- data.frame(Temperature = temperature_list)
predict(bmodel, newdata = new)
pred_list <- predict(bmodel, newdata = new)
data.frame(Temperature = temperature_list, pred_bike_count = pred_list)
#cars - speed(자동차 속도), dist(제동거리)
cor(cars$speed, cars$dist)
# 회귀모델
m <-lm(dist ~ speed, cars)
m
# 회귀모델 요약보고서
summary(m)
## 회귀 계수
codf(m)
## 회귀 계수
coef(m)
## 예측값(Fitted Values)
fitted(m)[1:4]
## 잔차: 예측 값과 실제 값 차이
residuals(m)[1:4]
## cars$dist = fitted(m) + residuals(m)
fitted(m)[1:4] + residuals(m)[1:4]
## 계수의 신뢰구간
confint(m)
## 잔차 제곱 합
deviance(m)
sum((cars$dist - predict(m, newdata = cars))^2)
## 예측
predict(m, newdata = cars)

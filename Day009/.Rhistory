# 데이터의 기본 특성
## 범주형 변수의 빈도수, 상대도수 구하기
### 절대 빈도수 구하기
library(MASS)
data <- data.frame(Cars93)
str(data)
summary(data)
table(data$Manufacturer)
### 상대도수 구하기: prop.table()
prop.table(summary(data$Manufacturer))
### 상대도수 구하기: prop.table()
prop.table(summary(data$Manufacturer)) *100
### 테이블 형태로 표현
prop.table(table(data$Manufacturer))
### 테이블 형태로 표현
round(prop.table(table(data$Manufacturer)) * 100, 2)
### 테이블 형태로 표현
paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%')
### 테이블 형태로 표현
data.frame(paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%'))
### 테이블 형태로 표현
vector(paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%'))
### 테이블 형태로 표현
list(paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%'))
### 테이블 형태로 표현
data.frame('(', paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%)'))
### 테이블 형태로 표현
data.frame(names(data$Manufacturer, c('(', paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%)'))
### 테이블 형태로 표현
data.frame('Freq' = table(data$Manufacturer),
### 테이블 형태로 표현
data.frame('Freq' = table(data$Manufacturer),
'Prop' = paste0(round(prop.table(table(data$Manufacturer)) * 100, 2), '%)'))
### 테이블 형태로 표현
data.frame('Freq' = table(data$Manufacturer),
'Prop' = paste0('(' ,round(prop.table(table(data$Manufacturer)) * 100, 2), '%)'))
paste(round(mean(data$Price), 1), '±', round(sd(data$Price), 1))
## 기술통계 분석에 유용한 함수
install.packages('moonBook')
library(moonBook)
?moonBook
mytable(data)
library(foreign)
raw <- read.spss('C:/k_digital/data/HN21/HN21_ALL.sav')
raw <- read.spss('C:/k_digital/data/HN21/HN21_ALL.sav', to.data.frame = T)
View(raw)
dat <- read.spss('C:/k_digital/data/HN21/test3.sav')
View(dat)
dat <- read.spss('C:/k_digital/data/HN21/test3.sav', to.data.frame = T)
View(dat)
#
install.packages('DataExplorer')
library(DataExplorer)
introduce(raw)
profile_missing(row)
profile_missing(raw)
# 결측률이 90% 이상인 데이터만 추출
raw_missing <- profile_missing(raw)
subset(raw_missing, pct_missing > 0.9)
library(dplyr)
arrange(subset(raw_missing, pct_missing > 0.9), desc(pct_missing))
psych::describe(raw)
install.packages(psych)
install.packages('psych')
install.packages("psych")
psych::describe(raw)
names(raw)
View(raw)
df <- read.spss('C:/k_digital/data/HN21/HN18_ALL.sav', to.data.frame = T, reencode = 'UTF-8')
df <- read.spss('C:/k_digital/data/HN18/HN18_ALL.sav', to.data.frame = T, reencode = 'UTF-8')
names(df)
## 추출할 변수: id, 성별, 나이, 당뇨병 유무,(19세 이상), 인슐린 주사, 공복 혈당, 당화혈색소
vars <- c('ID', 'sex', 'age', 'HE_DM', 'DE1_31', 'HE_glu','HE_HbA1c')
dafa_f <- select(df, vars)
rm(dafa_f)
data_f <- select(df, vars)
head(data_f, 10)
# 변수별 결측치 확인
introduce(data_f)
# 결측치 제거: na.omit() 결측이 존재하는 행을 제거하는 함수
data_f <- na.omit(data_f)
table(data_f$HE_DM)
data_f$HE_DM2 <- ifelse(data_f$HE_DM == 3, 1, 0)
table(data_f$HE_DM2)
# 인슐린 투여 DE1_31
## 0(아니오), 1(예), 8(비해당), 9(모름)
## 필요대상 추출
data_subj <- subset(data_f, data_f$HE_DM2 == 1 & data_f$DE1_31 == 0 | data_f$DE1_31 == 1)
nrow(data_subj)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램 + 밀도선)과 통계량을 이용하는 방법
### histogram
hist(data_subj)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램 + 밀도선)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu)
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램 + 밀도선)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.05), xlab = 'HE_glu(공복혈당)')
# t검정 수행시 사전에 정규성을 띄고 있어야 한다는 전제 조건
## 시각적인 방법(히스토그램 + 밀도선)과 통계량을 이용하는 방법
### histogram
hist(data_subj$HE_glu, freq = F, ylim = c(0, 0.02), xlab = 'HE_glu(공복혈당)')
### kernel density plot
lines(density(data_subj$HE_glu), col = 'orange', lwd = 2)
qqnorm(data_subj$HE_glu, col = 'green')
qqline(data_subj$HE_glu, col = 'orange', lwd = 2)
### Shapiro-Wilk test: 정규성 검정
### 귀무가설(H0): 정규분포를 따른다.
### 대립가설(H1, 연구가설, 나의 가설): 정규분포를 따르지 않는다.
shapiro.test(data_subj$HE_glu)
# Kolmogorov-Smirnov test
ks.test(data_subj$HE_glu, y = 'pnrom', alternative = 'two.side')
# Kolmogorov-Smirnov test
ks.test(data_subj$HE_glu, y = 'pnorm', alternative = 'two.side')
# 등분산성 검정
## 귀무가설: 두 그룹의 분산은 차이가 없다.
## 대립가설: 두 그룹의 분산은 차이가 있다.
var.test(data_subj$HE_glu ~ data_subj$DE1_31)
# 데이터 분석 결과
## 정규분포를 따르지 않고, 인슐린 투여 그룹 간 분산이 달랐다.
t.test(data_subj$HE_glu ~ data_subj$DE1_31, paired = F, var.equal = F)
# 데이터 분석 결과
## 정규분포를 따르지 않고, 인슐린 투여 그룹 간 분산이 달랐다.
t.test(data_subj$HE_glu ~ data_subj$DE1_31, paired = F, var.equal = F, conf.level = 0.5)
# 데이터 분석 결과
## 정규분포를 따르지 않고, 인슐린 투여 그룹 간 분산이 달랐다.
t.test(data_subj$HE_glu ~ data_subj$DE1_31, paired = F, var.equal = F, conf.level = 0.5)
# 일원배치 분산분석(one-way ANOVA)
## 세개 이상의 집단간의 평균 차이가 통계적으로 유의미한지 비교할 때 사용
## 가정: 정규성, 등분산성, 독립성
### 귀무가설: 모든 모집단의 평균은 동일하다.
### 대립가설: 모든 모집단의 평균은 동일하지 않다.
study <- read.csv('C:/k_digital/data/ANOVA 예제.csv', header = T)
# 정규성 확인
shapiro.test(subset(study, group == 'A')$time)
shapiro.test(study[study$group == 'B', 'time'])
shapiro.test(study[study$group == 'C', ]$time)
## 등분산성 확인
install.packages('lawstat')
library(lawstat)
levene.test(study$time, study$group, location = 'mean')
## ANOVA
result <- aov(time ~ group, data = study)
result
#                     group Residuals
# Sum of Squares  10091.975   224.397
# Deg. of Freedom         2        62
#
# Residual standard error: 1.902447
# Estimated effects may be unbalanced
summary(result)
# 보스턴 집값 예측: 회귀분석(선형회귀)
library(MASS)
# 보스턴 집값 예측: 회귀분석(선형회귀)
data(Boston)
# 해당 데이터셋을 파일로 저장
write.csv(Boston, file = 'boston.csv', row.names = T)
df <- read.csv('boston.csv', header = T, stringsAsFactors = F)
# 종속변수에 해당하는 medv(집값)을 제외하곡 데이터 추출
df <- df[, -1]
df <- read.csv('boston.csv', header = T, stringsAsFactors = F)
# 종속변수에 해당하는 medv(집값)을 제외하곡 데이터 추출
df <- df[, -15]
df <- read.csv('boston.csv', header = T, stringsAsFactors = F)
# 종속변수에 해당하는 medv(집값)을 제외하고 데이터 추출
df <- df[, -1]
install.packages('Hmisc')
library(Hmisc)
describe(df)
summary(medv ~ crim + zn, data = df)
# 데이터 전처리
## 결측치 확인
sum(is.na(df))
df[complete.cases(df), ] # 결측치가 없으면 TRUE
head(df, 10)
# 결측치 삭제
df <- na.omit(df)
install.packages(DMwR)
# 데이터 분할 - 학습, 성능평가
nrow(df)
## 랜덤 샘플링: train(70%), test(30%)
df_idx <- sample(1:506, 300)
df_train <- df[df_idx, ]
df_test <- df[-df_idx, ]
nrow(df_train)
nrow(df_test)
# 다중회귀분석
result <- lm(medv ~ ., data = df_train)
summary(result)
## 다중공선선: 독립변수들 간에 지나친 상관관계가 존재한다면, 그 데이터의 설명력은 낮아짐
### 팽창지수(vif)
install.packages('car')
library(car)
vif(result)
# 상관관계 - 시각화, 통계량(cor)
plot(df_train)
# 이상치 분석
outlierTest(df_train)
model <- lm(medv ~ ., df_train)
model
model2 <- step(model, direction = 'both') # step(단계적 변수 선택)
# - chas     1    134.49 5947.6 918.09
# - black    1    134.74 5947.9 918.10
# - crim     1    168.99 5982.1 919.82
# - zn       1    174.22 5987.3 920.09
# - rad      1    289.23 6102.3 925.79
# - nox      1    372.74 6185.8 929.87
# - dis      1    644.62 6457.7 942.78
# - ptratio  1    752.82 6565.9 947.76
# - lstat    1   1248.05 7061.2 969.57
# - rm       1   1253.65 7066.8 969.81
model3 <- lm(medv ~ crim + zn + chas + nox + rm + dis + rad + tax + ptratio +
black + lstat, df_train)
model3
# Coefficients:
# (Intercept)         crim           zn         chas          nox           rm
# 33.780457    -0.103718     0.047856     3.084590   -18.315039     4.036411
# dis          rad          tax      ptratio        black        lstat
# -1.301758     0.306364    -0.010406    -0.972972     0.008811    -0.458947
summary(model3)
df_test <- df_test[-14, ]
df_test <- df[-df_idx, ]
df_test <- df_test[, -14]
actual <- df_train$medv
expect <- predict(model2, newdata = df_test, type = 'class')
result_df <- data.frame(actual, expect)
expect <- predict(model2, newdata = df_test)
result_df <- data.frame(actual, expect)
result_df
t.test(result_df)
df_test <- df[-df_idx, ]
df_test <- df_test[,-14]
expect <- predict(model2, newdata = df_test)
df_test <- df[-df_idx,]
actual <- df_train$medv
result_df <- data.frame(actual, expect)
df_test <- df_test[,-14]
expect <- predict(model2, newdata = df_test)
df_test <- df[-df_idx,]
actual <- df_test$medv
result_df <- data.frame(actual, expect)
result_df
#     actual    expect
# 1     24.0 29.554054
# 4     33.4 28.286172
# 7     22.9 23.088065
# 8     27.1 20.147697
# 11    15.0 19.815848
# 17    23.1 19.904609
# 20    18.2 17.892105
t.test(result_df)
expect <- predict(model, newdata = df_test)
result_df <- data.frame(actual, expect)
result_df
#     actual    expect
# 1     24.0 29.537242
# 4     33.4 28.278065
# 7     22.9 23.121417
# 8     27.1 20.230874
# 11    15.0 19.895434
# 17    23.1 19.828122
# 20    18.2 17.881696
t.test(result_df)
expect <- predict(model3, newdata = df_test)
result_df <- data.frame(actual, expect)
result_df
#     actual    expect
# 1     24.0 29.554054
# 4     33.4 28.286172
# 7     22.9 23.088065
# 8     27.1 20.147697
# 11    15.0 19.815848
# 17    23.1 19.904609
# 20    18.2 17.892105
t.test(result_df)
View(df_train)
lmodel<- lm(medv ~ crim, df_train)
lmodel
# Coefficients:
# (Intercept)     crim
# 23.4020      -0.3387
summary(lmodel)
lmodel<- lm(medv ~ rm, df_train)
lmodel
# Coefficients:
# (Intercept)     crim
# 23.4020      -0.3387
summary(lmodel)
lmodel<- lm(medv ~ crim+ rm, df_train)
lmodel
# Coefficients:
# (Intercept)     crim
# 23.4020      -0.3387
summary(lmodel)
lmodel<- lm(medv ~ crim + zn + rm, df_train)
lmodel
# Coefficients:
# (Intercept)     crim
# 23.4020      -0.3387
summary(lmodel)

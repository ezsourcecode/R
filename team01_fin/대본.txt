1. 안녕하세요 건물별 전력사용량 예측을 주제로 미니 프로젝트를 발표할 electric shock팀 발표자 안은지입니다. 팀원은 문영재, 서강석, 조은겸을 포함한 총 4명입니다.

2. 목차는 이렇게 구성되었습니다.

3. 첫 프로젝트이기에 의미있는 주제를 선정하고 싶었습니다. 환경분야이면서 가장 밀접한 실제 데이터 분석의 대표적 사례에 전력수요 예측이 있다는 걸 알았고, 데이콘 공모전에 이 주제가 올라왔기에 가장 최적의 주제라 여겨 선정하였습니다.

4. 앞서 언급했듯이 대회 참가도 겸하기에 프로젝트는 대회 기준을 준수하기 위해 SMAPE 기준 0.1 미만을 목표로 설정하고, 실제 전력 사용량과 최대한 가깝게 예측하려 노력하였습니다.

5. 저희 팀은 이 미니 프로젝트를 통해 기존에 배웠던 지식 활용 및 머신 러닝 분석을 경험해보고 더 나아가 커리어에도 도움이 될 대회 참가 경험을 쌓는 것이 목적이었습니다.

6. 프로젝트 진행은 도표로 보시는 것 같이 큰 틀에서 이 흐름대로 진행하였습니다. 

7. 초기 계획보다 데이터 분석에서 시간이 더 소요되어 뒤 일정이 밀리긴 하였으나 slack과 같은 툴을 사용하면서 일정관리에 더 차질이 생기진 않았던 것 같습니다.

8. 데이터 탐색에 앞서 선행연구들을 확인했습니다. 데이콘에서는 과거 전력 사용량 예측 대회가 몇차례 있었기에 참고할 자료가 많았습니다. 대다수가 파이썬으로 작성되었으나 데이터 탐색과 변수 설정, 분석 방법 등 많은 아이디어를 얻을 수 있었습니다.

9. 논문을 통해서 어떤 변수들로 어떤 모델링을 통해 효과적인 전력 사용량을 예측했는지,

10. 주요 변수들을 참고할 수 있었습니다.

11. 아직 데이터 셋을 설명하지 않았지만, 결론부터 말하자면 저희는 건물별로 모델링을 진행했습니다. 선행연구와 변수의 상관관계를 분석해 건물 단위로 모델을 설정했을 때의 장점이 많다는 것을 알 수 있었는데 간단히 요약하자면 개별 특성을 반영해 모델링을 하면 최적화가 용이하다는 것입니다.

12. 데이터셋 구성으로는 훈련을 위한 train 데이터에 일시별 기온부터 기상 정보 및 전력소비량까지 담겨있습니다. 

13. 다음으로 building info는 100개의 건물 정보가 담겨있고 2개의 데이터셋은 건물번호로 연결할 수 있음을 확인할 수 있습니다.

14. test 데이터에는 건물번호와 일시, 기상정보로 train 데이터보다 열이 더 적습니다.

15. 마지막으로 submisson 제출용 데이터는 건물번호와 일시를 조합한 ID와 예측 값을 제출해야 할 열인 answer로 구성되어있습니다.

16. 데이터를 확인 후 가장 먼저 한 것은 결측치가 있는 열을 핸들링하는 작업으로 변수들의 결측치를 어떻게 보간할지 고민했습니다. 강수량의 경우 파란색칸과 빨강색 칸을 비교해봤을 때 빨간칸은 파란색보다 비교적 습도가 낮은 편으로 강수량의 NA값은 비가 내리지 않아 측정할 수 없었던 것으로 판단해 NA값을 0으로 대체했습니다.

17. 다음은 일조와 일사 결측치입니다. 일조와 일사는 태양으로 인해 측정되는 값이기에 NA값이 없는 데이터를 보더라도 밤시간대는 측정값이 0으로 나와있습니다. 해서 결측치를 0으로 대치했습니다.

18. 앞에 나왔던 변수들과는 달리 풍속과 습도는 결측치를 제거하거나, 0으로 변환할 수는 없는 값입니다. 시간의 연속성을 고려해 회귀 대치법을 사용해 앞 뒤 값의 사이 값으로 보간했습니다.

19. 일시는 문자형으로 주어졌습니다. 그렇지만 LSTM, ARIMA 모델을 사용하려면 시계열 형식이어야 하기에 시계열로 형식을 변환했고,

20. lubridate 패키지로 요일과 평일/휴일을 알 수 있는 범주형 변수들을 생성했습니다. 

21. join()로 train과 building info 데이터셋을 병합해 훈련용 데이터셋을 만들었습니다.

22. 훈련 세트 변수는 예측에 미미한 영향을 미치는 변수들을 제외하고, 총 15개의 변수들을 선정했습니다.

23. 앞에 말했던 변수 선정 예시입니다.

24. 모델을 만드는 과정에서 가시적으로 데이터를 탐색하기 위해 여러 그래프로 데이터의 특성을 파악했습니다. 이 그래프의 전력사용량 저점과 고점 사이를 보면 올라갔다 내려갔다 하는구간이 일정한 간격임을 알 수 있습니다. 날짜로 확인하면 휴일보다 평일의 전력사용량이 더 많은 것이 나타납니다.

25. 요일별로 보면 일요일이 가장 사용량이 적어 그 차이는 더 명확합니다.

26. 건물의 유형별로 보면 아파트가 가장 적게 쓰고, 대학이 가장 전력을 많이 사용합니다. 

27. 이번엔 건물 유형별로 주중과 주말을 비교해볼까요? 왼쪽은 공공기관으로 주중과 주말 전력 사용량에 차이가 있습니다. 오른쪽은 백화점 및 아울렛으로 주중과 주말의 차이가 거의 없습니다. 동일한 유형 안에서는 어떨까요? 

28. 둘다 지식산업센터이지만 왼쪽은 사용량이 일정하고, 오른쪽은 주말에 확 줄어든 걸 보면 같은 유형이라도 사용 패턴이 다른 걸 알 수 있습니다.

29. 훈련데이터는 여름 3개월의 데이터만 있습니다. 7월 말에 살짝 사용량이 감소하기는 하지만 추세선을 보면 6월부터 점점 사용량이 올라가는 게 보입니다. 일반적으로 6월과 7,8월을 비교했을 때 온도는 올라가고, 비가 오는 날이 많기에 기상 변수와 관련이 있다고 추측했습니다.

30. 전체 건물에서 변수간 상관관계 그래프로 박스를 보면 기상변수와 워킹데이가 약하지만 양의 상관관계를 보입니다.

31. 각 건물별로 다시 확인해보면 건물마다 상관관계가 다르게 나타남을 알 수 있습니다.

32. 앞서 보신 것과 같이 건물마다 사용 패턴도 다르고, 상관관계도 건물마다 강도가 다르기에 건물별로 잘 맞는 모델을 생성하기로 방향을 잡았습니다. 그래서 회귀 분석과 머신러닝을 모델로 사용하려고 했고, 그중 논문에 나온 LSTM을 쓰고 싶었지만 r에서는 구동이 어려워 다른 모델들을 사용해봤습니다.

33. 모델의 평가지표에 사용할 수식입니다.

34. 구동한 모델 코드를 보여드리기 전에 간단히 모델을 설명하겠습니다. 가장 먼저 수업에서 배운 회귀분석입니다. 독립변수와 종속변수간의 관계로 예측에서 쉽게 사용할 수 있습니다. 하지만 분석이 쉬운만큼 가정이 옳지 않다면 결과가 오용되기도 쉬운 모델입니다.

35. KNN은 머신러닝 모델로 k값에 따른 중심거리로 데이터를 분류합니다. 적절한 k값을 찾으면 간단하고 효과적으로 예측에 사용할 수 있습니다.

36. GBM은 그래디언트 부스트 모델로 앙상블 기법 중 하나입니다. 변형으로 XGBoost, LightGBM, CatBoost 등이 있으며 하이퍼파라미터 튜닝이 중요합니다.

37. SVM은 머신러닝 분류 모델로 각 범주가 잘 분류되도록 마진을 최대로 한 경계를 찾는 것이 특징입니다. 그림과 같이 선으로 나누기에 비선형 분류시에는 데이터를 고차원으로 사상하는 작업이 필요합니다. 분류와 예측 문제에 동시에 활용가능하다는 장점이 있습니다.

38. 5번 건물을 예시로 상관관계를 보면 습도 변수를 뺀 나머지들은 양의 상관관계를 확인할 수 있습니다.

39. 앞서 나온 변수들을 토대로 회귀분석을 실행한 결과 온도 변수의 t값이 가장 높게 나와 전력 소비량에 가장 큰 영향을 미치는 것을 알 수 있습니다. 이런식으로 테스트를 진행해봤습니다.

40. 최종 모델을 만들기 위해 앞서 작업한 것들과 다른 디렉토리로 파일을 새로 생성했습니다. 디플라이어와 메트릭스를 제외한 패키지들은 각 모델들을 갖고 있는 패키지입니다. 그중 e1071은 svm이 들어있습니다.

41. 전처리한 데이터들을 저장한 파일을 깃허브에서 불러와 의미없는 열번호를 지웁니다. smape뿐만 아니라 다른 평가 방식을 각 모델별로 저장합니다.

42. 그 다음 모델의 오차를 측정할 함수를 생성합니다.

43.각 분석 방법들을 모두 반복문으로 각 건물별로 모델을 생성해 결과를 저장했습니다. lm()함수로 변수를 지정하고, step()함수로 모든 변수를 포함한 모델부터 시작해 독립변수를 하나씩 추가/제거하여 AIC값이 가장 작게 나오는 종속변수를 선택하는 기법을 사용했습니다.

44. svm()함수에는 회귀분석 모델을 엡실론 방식을 택하고, 커널은 선형 관계를 나타내는 모델을 만들었습니다.

45. gbm() 함수는 가우시안 분포로 설정, 생성할 트리 수는 100, 트리의 최대 깊이는 5, 각 트리의 기여도를 제한할 축소율은 0.05, 각 노드 내에서 최소 관측치는 23으로 지정했습니다.

46. train.kknn() 함수는 최대 이웃의 개수를 2로 설정하고, 커널은 옵티멀로 데이터 분포에 따라 자동으로 선택하게 하였습니다.

47. 이렇게 돌린 모델들의 SAMPE 값의 평균을 비교해보니 GBM의 성능이 가장 좋았습니다. 다른 평가 점수에서도 GBM이 가장 나았으나 평가 기준이 SAMPE기에 SAMPE 기준 하나만 그래프로 보여드렸습니다. 대회 마감일이 아직 더 남았기에 남은 기간 동안 더 보완해 제출할 것입니다.

. 마지막으로 각자 소감을 짧게 말하며 발표를 마무리하도록 하겠습니다.





